{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93650ae6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '_isfilestore'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_27269/915445653.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0mdf_buffer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m \u001b[0mdf_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartition_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartition_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/datapipeline/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/datapipeline/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(self, path, engine, compression, index, partition_cols, storage_options, **kwargs)\u001b[0m\n\u001b[1;32m   2683\u001b[0m             \u001b[0mpartition_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartition_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2685\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2686\u001b[0m         )\n\u001b[1;32m   2687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/datapipeline/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mto_parquet\u001b[0;34m(df, path, engine, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mpartition_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartition_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m     )\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/datapipeline/lib/python3.7/site-packages/pandas/io/parquet.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, df, path, compression, index, storage_options, partition_cols, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m                     \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m                     \u001b[0mpartition_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartition_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m                 )\n\u001b[1;32m    192\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/datapipeline/lib/python3.7/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36mwrite_to_dataset\u001b[0;34m(table, root_path, partition_cols, partition_filename_cb, filesystem, use_legacy_dataset, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/datapipeline/lib/python3.7/site-packages/pyarrow/parquet.py\u001b[0m in \u001b[0;36m_mkdir_if_not_exists\u001b[0;34m(fs, path)\u001b[0m\n\u001b[1;32m   2009\u001b[0m         \u001b[0mAdditional\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mParquetWriter\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mSee\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0;32mfor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mParquetWriter\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0minformation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2011\u001b[0;31m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2012\u001b[0m     \u001b[0mExamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m     \u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_isfilestore'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data1 = [\n",
    "    {\n",
    "        \"id\": 0,\n",
    "        \"price\": \"0.00976300\",\n",
    "        \"qty\": \"0.29000000\",\n",
    "        \"quoteQty\": \"0.00283127\",\n",
    "        \"time\": 1630923495816,\n",
    "        \"isBuyerMaker\": False,\n",
    "        \"isBestMatch\": True\n",
    "    },\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"price\": \"0.00976500\",\n",
    "        \"qty\": \"0.42000000\",\n",
    "        \"quoteQty\": \"0.00410130\",\n",
    "        \"time\": 1630923495820,\n",
    "        \"isBuyerMaker\": False,\n",
    "        \"isBestMatch\": True\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"price\": \"0.00976500\",\n",
    "        \"qty\": \"0.32100000\",\n",
    "        \"quoteQty\": \"0.00313456\",\n",
    "        \"time\": 1630923495820,\n",
    "        \"isBuyerMaker\": False,\n",
    "        \"isBestMatch\": True\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"price\": \"0.00976500\",\n",
    "        \"qty\": \"3.00000000\",\n",
    "        \"quoteQty\": \"0.02929500\",\n",
    "        \"time\": 1630923495823,\n",
    "        \"isBuyerMaker\": False,\n",
    "        \"isBestMatch\": True\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"price\": \"0.00976500\",\n",
    "        \"qty\": \"1.32700000\",\n",
    "        \"quoteQty\": \"0.01295815\",\n",
    "        \"time\": 1630923495823,\n",
    "        \"isBuyerMaker\": False,\n",
    "        \"isBestMatch\": True\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"price\": \"0.00976500\",\n",
    "        \"qty\": \"0.47400000\",\n",
    "        \"quoteQty\": \"0.00462861\",\n",
    "        \"time\": 1630923495823,\n",
    "        \"isBuyerMaker\": False,\n",
    "        \"isBestMatch\": True\n",
    "    },\n",
    "    {\n",
    "        \"id\": 6,\n",
    "        \"price\": \"0.00976500\",\n",
    "        \"qty\": \"0.06200000\",\n",
    "        \"quoteQty\": \"0.00060543\",\n",
    "        \"time\": 1630923495823,\n",
    "        \"isBuyerMaker\": False,\n",
    "        \"isBestMatch\": True\n",
    "    },\n",
    "    {\n",
    "        \"id\": 7,\n",
    "        \"price\": \"0.00976500\",\n",
    "        \"qty\": \"0.46400000\",\n",
    "        \"quoteQty\": \"0.00453096\",\n",
    "        \"time\": 1630923495823,\n",
    "        \"isBuyerMaker\": False,\n",
    "        \"isBestMatch\": True\n",
    "    },\n",
    "    {\n",
    "        \"id\": 8,\n",
    "        \"price\": \"0.00976500\",\n",
    "        \"qty\": \"2.67500000\",\n",
    "        \"quoteQty\": \"0.02612137\",\n",
    "        \"time\": 1630923495824,\n",
    "        \"isBuyerMaker\": False,\n",
    "        \"isBestMatch\": True\n",
    "    },\n",
    "    {\n",
    "        \"id\": 9,\n",
    "        \"price\": \"0.00976500\",\n",
    "        \"qty\": \"1.98300000\",\n",
    "        \"quoteQty\": \"0.01936399\",\n",
    "        \"time\": 1630923495825,\n",
    "        \"isBuyerMaker\": False,\n",
    "        \"isBestMatch\": True\n",
    "    }\n",
    "]\n",
    "\n",
    "data2 = [\n",
    "    {\n",
    "        \"id\": 0,\n",
    "        \"price\": \"0.00976300\",\n",
    "        \"qty\": \"0.29000000\",\n",
    "        \"quoteQty\": \"0.00283127\",\n",
    "        \"time\": 1630923495816,\n",
    "        \"isBuyerMaker\": True,\n",
    "        \"isBestMatch\": True\n",
    "    },\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"price\": \"0.00976500\",\n",
    "        \"qty\": \"0.42000000\",\n",
    "        \"quoteQty\": \"0.00sdas410130\",\n",
    "        \"time\": 12312312311,\n",
    "        \"isBuyerMaker\": True,\n",
    "        \"isBestMatch\": True\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"price\": \"0.asdasda\",\n",
    "        \"qty\": \"0.32100000\",\n",
    "        \"quoteQty\": \"0.00313456\",\n",
    "        \"time\": 1630923495820,\n",
    "        \"isBuyerMaker\": False,\n",
    "        \"isBestMatch\": True\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"price\": \"0.asdasd\",\n",
    "        \"qty\": \"3.00000000\",\n",
    "        \"quoteQty\": \"0.02929500\",\n",
    "        \"time\": 1630923495823,\n",
    "        \"isBuyerMaker\": False,\n",
    "        \"isBestMatch\": True\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"price\": \"0.asdasd\",\n",
    "        \"qty\": \"1.32700001\",\n",
    "        \"quoteQty\": \"0.01295815\",\n",
    "        \"time\": 1630923495823,\n",
    "        \"isBuyerMaker\": False,\n",
    "        \"isBestMatch\": True\n",
    "    }\n",
    "]\n",
    "\n",
    "df1 = pd.json_normalize(data1)\n",
    "\n",
    "df2 = pd.json_normalize(data1)\n",
    "\n",
    "df1['symbol'] = 'TEST1'\n",
    "df1['date'] = pd.to_datetime(df1['time'],unit='ms')\n",
    "df1[['day', 'month', 'year', 'hour']] = df1.date.apply(lambda x: (x.day, x.month, x.year, x.hour)).tolist()\n",
    "df2['symbol'] = 'TEST1'\n",
    "df2['date'] = pd.to_datetime(df['time'],unit='ms')\n",
    "df2[['day', 'month', 'year', 'hour']] = df2.date.apply(lambda x: (x.day, x.month, x.year, x.hour)).tolist()\n",
    "partition_cols = ['symbol', 'year', 'month', 'day', 'hour']\n",
    "\n",
    "from io import BytesIO\n",
    "df_bytes = df.to_parquet(partition_cols=partition_cols)\n",
    "df_buffer = BytesIO(df_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e29bd28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b6fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
